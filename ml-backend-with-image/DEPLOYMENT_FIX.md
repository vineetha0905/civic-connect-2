# ML Backend Deployment Fix - Complete Guide

## ğŸ”§ Critical Fixes Applied

### 1. CORS Configuration (FIXED)
- **Issue**: CORS headers not being sent, causing browser to block requests
- **Fix**: Simplified to use `allow_origins=["*"]` with `allow_credentials=False`
- **Location**: `app/main.py` lines 29-50

### 2. FastAPI App Path (FIXED)
- **Issue**: Dockerfile was using wrong module path
- **Fix**: Changed from `app:app` to `app.main:app`
- **Location**: `Dockerfile` and `start.sh`

### 3. Port Configuration (FIXED)
- **Issue**: Hardcoded port, not using Render's PORT env var
- **Fix**: Uses `$PORT` environment variable with fallback
- **Location**: `start.sh` and `render.yaml`

### 4. Health Check Endpoint (ADDED)
- **Issue**: No health check for Render
- **Fix**: Added `/health` endpoint
- **Location**: `app/main.py` lines 104-107

### 5. OPTIONS Handler (ADDED)
- **Issue**: CORS preflight requests might fail
- **Fix**: Added explicit OPTIONS handler for `/submit`
- **Location**: `app/main.py` lines 110-113

## ğŸš€ Deployment Steps on Render

### Option 1: Using render.yaml (Recommended)
1. Make sure `render.yaml` is in the `ml-backend-with-image` directory
2. In Render dashboard:
   - Create new Web Service
   - Connect your GitHub repo
   - Render will auto-detect `render.yaml`
   - Or manually set:
     - **Root Directory**: `ml-backend-with-image`
     - **Environment**: `Python 3`
     - **Build Command**: `pip install --upgrade pip && pip install -r requirements.txt`
     - **Start Command**: `uvicorn app.main:app --host 0.0.0.0 --port $PORT --workers 1 --timeout-keep-alive 75`

### Option 2: Using Dockerfile
1. In Render dashboard:
   - Create new Web Service
   - Connect your GitHub repo
   - **Root Directory**: `ml-backend-with-image`
   - **Docker**: Enable Docker
   - Render will use the Dockerfile automatically

### Environment Variables to Set in Render:
```
PORT=7860
CORS_ORIGINS=*
PYTHONUNBUFFERED=1
```

## âœ… Verification Steps

After deployment, test these endpoints:

1. **Health Check**: 
   ```
   GET https://civic-connect-ml.onrender.com/health
   ```
   Should return: `{"status": "healthy", "service": "ML Backend"}`

2. **Root Endpoint**:
   ```
   GET https://civic-connect-ml.onrender.com/
   ```
   Should return: `{"status": "ML API running", "version": "1.0.0"}`

3. **CORS Test** (from browser console on your frontend):
   ```javascript
   fetch('https://civic-connect-ml.onrender.com/health', {
     method: 'GET',
     headers: {'Content-Type': 'application/json'}
   }).then(r => r.json()).then(console.log)
   ```
   Should work without CORS errors.

## ğŸ› Troubleshooting

### If you still get CORS errors:
1. Check Render logs - look for "CORS Configuration" output
2. Verify the service is actually running (check `/health` endpoint)
3. Make sure `allow_credentials=False` (it's set in code)
4. Clear browser cache and try again

### If you get 502 Bad Gateway:
1. Check Render logs for startup errors
2. Verify all dependencies are installed
3. Check if the port is correct
4. Make sure `app.main:app` is the correct path

### If models fail to load:
1. Check Render logs for import errors
2. Verify all files in `app/` directory are present
3. Check if transformers/torch models can download (might need internet access)

## ğŸ“ Key Files Modified

1. `app/main.py` - CORS fix, health endpoint, OPTIONS handler
2. `Dockerfile` - Fixed module path, PORT support
3. `start.sh` - Added PORT support, better logging
4. `render.yaml` - Complete Render configuration

## ğŸ¯ Expected Behavior

After deployment:
- âœ… CORS headers are sent with every response
- âœ… OPTIONS preflight requests are handled
- âœ… Health check endpoint works
- âœ… `/submit` endpoint accepts POST requests
- âœ… All Vercel deployments can access the API
- âœ… No more 502 or CORS errors

